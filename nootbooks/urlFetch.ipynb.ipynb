{"cells":[{"cell_type":"code","execution_count":16,"id":"97b654d8-b162-44d5-ab57-725d9e10695e","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":null,"execution_start_time":null,"livy_statement_state":null,"normalized_state":"waiting","parent_msg_id":"95e41a5e-f0c2-463a-8736-fcb4a50f3b09","queued_time":"2024-11-10T19:46:43.2195263Z","session_id":null,"session_start_time":null,"spark_pool":null,"state":"waiting","statement_id":null,"statement_ids":null},"text/plain":["StatementMeta(, , , Waiting, , Waiting)"]},"metadata":{},"output_type":"display_data"}],"source":["# df = spark.sql(\"SELECT * FROM InFreGen.task LIMIT 1000\")\n","# display(df)\n","# # 删除所有给定taskID的pic\n","# spark.sql(\"DELETE FROM InFreGen.pic WHERE taskID = {}\".format(taskID))\n","# taskID = 19"]},{"cell_type":"code","execution_count":17,"id":"8ff2a0b8-3a27-4094-99da-59a1b14d2448","metadata":{"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":null,"execution_start_time":null,"livy_statement_state":null,"normalized_state":"waiting","parent_msg_id":"e4c29793-9b3e-43bc-a941-bc8aa25af9ae","queued_time":"2024-11-10T19:46:43.220363Z","session_id":null,"session_start_time":null,"spark_pool":null,"state":"waiting","statement_id":null,"statement_ids":null},"text/plain":["StatementMeta(, , , Waiting, , Waiting)"]},"metadata":{},"output_type":"display_data"}],"source":["# Import required libraries\n","from enum import Enum\n","import requests\n","from pyspark.sql import functions as F\n","import json\n","\n","# Unsplash API access key\n","ACCESS_KEY = 'YOUR KEY HERE'\n","\n","\n","class Orientation(Enum):\n","    \"\"\"Enum class to represent image orientation options\"\"\"\n","    UNKNOWN = 0\n","    LANDSCAPE = 1  # Landscape orientation\n","    PORTRAIT = 2   # Portrait orientation\n","    SQUARISH = 3   # Square orientation\n","\n","    def get_lower_value(self):\n","        \"\"\"Returns lowercase string value of orientation for API params\"\"\"\n","        if self == Orientation.UNKNOWN:\n","            return \"\"\n","        return self.name.lower()\n","\n","\n","class UnsplashClient:\n","    \"\"\"Client class to interact with the Unsplash API\"\"\"\n","    \n","    def __init__(self, access_key):\n","        \"\"\"Initialize client with access key and base configuration\"\"\"\n","        self.access_key = access_key\n","        self.base_url = 'https://api.unsplash.com/'\n","        self.headers = {\n","            'Accept-Version': 'v1',\n","            'Authorization': f'Client-ID {self.access_key}'\n","        }\n","\n","    def get_random_image(self, query: str = None, orientation: Orientation = Orientation.UNKNOWN):\n","        \"\"\"\n","        Fetch a random image from Unsplash\n","        Args:\n","            query: Search term for the image\n","            orientation: Desired image orientation\n","        Returns:\n","            JSON response if successful, None if failed\n","        \"\"\"\n","        url = self.base_url + 'photos/random'\n","        params = {\n","            'query': query,\n","            'orientation': orientation.get_lower_value()\n","        }\n","        response = requests.get(url, headers=self.headers, params=params)\n","        return response.json() if response.status_code == 200 else None\n","\n","    def search_images(\n","            self, query: str,\n","            page: int = 1,\n","            per_page: int = 30,\n","            orientation: Orientation = Orientation.UNKNOWN\n","    ):\n","        \"\"\"\n","        Search for images on Unsplash\n","        Args:\n","            query: Search term\n","            page: Page number for pagination\n","            per_page: Number of results per page\n","            orientation: Desired image orientation\n","        Returns:\n","            JSON response if successful, None if failed\n","        \"\"\"\n","        url = self.base_url + 'search/photos'\n","        params = {\n","            'query': query,\n","            'page': page,\n","            'per_page': per_page,\n","        }\n","        if orientation != Orientation.UNKNOWN:\n","            params['orientation'] = orientation.get_lower_value()\n","        response = requests.get(url, headers=self.headers, params=params)\n","        print(response.status_code)\n","        # 400 error \n","        return response.json() if response.status_code == 200 else None\n","\n","# Initialize Unsplash client with access key\n","client = UnsplashClient(ACCESS_KEY)"]},{"cell_type":"code","execution_count":18,"id":"6aa029c7-a5e1-4cc7-97ba-4fc347343359","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":null,"execution_start_time":null,"livy_statement_state":null,"normalized_state":"waiting","parent_msg_id":"0c639b21-a63e-4dee-8366-01fe2e81a591","queued_time":"2024-11-10T19:46:43.2210254Z","session_id":null,"session_start_time":null,"spark_pool":null,"state":"waiting","statement_id":null,"statement_ids":null},"text/plain":["StatementMeta(, , , Waiting, , Waiting)"]},"metadata":{},"output_type":"display_data"}],"source":["# Import required random module for selecting random keywords and images\n","import random\n","\n","# Query the task table to get task details for the given taskID\n","task_row = spark.sql(\"SELECT * FROM InFreGen.task WHERE taskID = {}\".format(taskID)).collect()[0]\n","print(task_row)\n","# Row(taskID=12, userInput='I want to do medical image cancer detection', keyword=None, num=8, resolution='1024x1024', sizeChoice='small', State=0)\n","\n","def searchPerTask(task_row) -> list[dict]:\n","    \"\"\"\n","    Search and fetch images from Unsplash based on task parameters\n","    \n","    Args:\n","        task_row: Row object containing task details like keywords, number of images etc.\n","        \n","    Returns:\n","        list[dict]: List of dictionaries containing image metadata and URLs\n","    \"\"\"\n","    # Split comma-separated keywords into list\n","    keywords = task_row['keyword'].split(',')\n","    print(\"keyword:\", keywords)\n","    \n","    # Initialize empty list to store image metadata\n","    pic_table = []\n","    count = 0\n","    \n","    # Keep fetching images until we reach desired count\n","    while count < task_row['num']:\n","        # Randomly select a keyword from available keywords\n","        keyword = random.choice(keywords)\n","        print(\"Chosen keyword: \" + keyword)\n","\n","        # Search Unsplash with selected keyword\n","        search_results = client.search_images(query=keyword, page=1, per_page=30, orientation=Orientation.SQUARISH)\n","        try:\n","            # Get URLs for a random image from search results\n","            image_urls = random.choice(search_results['results'])['urls']\n","        except:\n","            # Skip if no results found\n","            continue\n","            \n","        # Create metadata dictionary for the image\n","        new_row = {\n","            'taskID': task_row['taskID'],\n","            'picID': count,\n","            'Resolution': task_row['resolution'],\n","            'sizeChoice': task_row['sizeChoice'],\n","            'operations': \"\",\n","            'operationsReturn': \"\",\n","            'url': json.dumps(image_urls),\n","            'State': 0,\n","            'originalPicPath': \"\",\n","            'curPicPath': \"\",\n","            'keywords': keyword,\n","            'finalPicPath': \"\",\n","        }\n","        pic_table.append(new_row)\n","        count += 1\n","    return pic_table\n","    \n","# Import IntegerType for type casting\n","from pyspark.sql.types import IntegerType\n","\n","# Create DataFrame from image metadata and cast columns to proper types\n","pic_df = spark.createDataFrame(searchPerTask(task_row))\n","pic_df = pic_df.withColumn(\"taskID\", pic_df[\"taskID\"].cast(IntegerType()))\n","pic_df = pic_df.withColumn(\"picID\", pic_df[\"picID\"].cast(IntegerType()))\n","pic_df = pic_df.withColumn(\"State\", pic_df[\"State\"].cast(IntegerType()))\n","\n","# Save DataFrame as Delta table\n","pic_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"InFreGen.pic\")"]}],"metadata":{"dependencies":{"lakehouse":{"default_lakehouse":"89188849-0b09-4102-bcab-2cfcf5509b4b","default_lakehouse_name":"InFreGen","default_lakehouse_workspace_id":"a136438a-0d8b-4308-9f2f-c74ea9668405"}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"synapse_widget":{"state":{},"version":"0.1"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
